{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/vineethsuhas/vineeth/handsOn/hackathons/My First Project-24bc12c3bf85.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_excel('aap_air_quality_database_2018_v14.xlsx', sheet_name=1, header=0, skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>iso3</th>\n",
       "      <th>Country</th>\n",
       "      <th>City/Town</th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual mean, ug/m3</th>\n",
       "      <th>Temporal coverage</th>\n",
       "      <th>note on converted PM10</th>\n",
       "      <th>Annual mean, ug/m3.1</th>\n",
       "      <th>Temporal coverage.1</th>\n",
       "      <th>note on converted PM2.5</th>\n",
       "      <th>Number and type of monitoring stations</th>\n",
       "      <th>Reference for air quality</th>\n",
       "      <th>Database version (year)</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Europe (LMIC)</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Korce</td>\n",
       "      <td>2015</td>\n",
       "      <td>45</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>Measured</td>\n",
       "      <td>30</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>Measured</td>\n",
       "      <td>1 Suburban-Background</td>\n",
       "      <td>The European Environmental Agency (EEA) [downl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Europe (LMIC)</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Korce</td>\n",
       "      <td>2016</td>\n",
       "      <td>40</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>Measured</td>\n",
       "      <td>29</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>Measured</td>\n",
       "      <td>1 Suburban-Background</td>\n",
       "      <td>The European Environmental Agency (EEA) [downl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Europe (LMIC)</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>2013</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Measured</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Measured</td>\n",
       "      <td>1 station, traffic, urban</td>\n",
       "      <td>European Environment Agency, Air quality e-rep...</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Europe (LMIC)</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Vlore</td>\n",
       "      <td>2014</td>\n",
       "      <td>15</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>Measured</td>\n",
       "      <td>(10)-converted value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Converted</td>\n",
       "      <td>1 Urban-Background</td>\n",
       "      <td>The European Environmental Agency (EEA) [downl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Europe (LMIC)</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Vlore</td>\n",
       "      <td>2015</td>\n",
       "      <td>19</td>\n",
       "      <td>&gt;75%</td>\n",
       "      <td>Measured</td>\n",
       "      <td>(13)-converted value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Converted</td>\n",
       "      <td>1 Urban-Background</td>\n",
       "      <td>The European Environmental Agency (EEA) [downl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Region iso3  Country City/Town  Year Annual mean, ug/m3  \\\n",
       "0  Europe (LMIC)  ALB  Albania     Korce  2015                 45   \n",
       "1  Europe (LMIC)  ALB  Albania     Korce  2016                 40   \n",
       "2  Europe (LMIC)  ALB  Albania    Tirana  2013                 32   \n",
       "3  Europe (LMIC)  ALB  Albania     Vlore  2014                 15   \n",
       "4  Europe (LMIC)  ALB  Albania     Vlore  2015                 19   \n",
       "\n",
       "  Temporal coverage note on converted PM10  Annual mean, ug/m3.1  \\\n",
       "0              >75%               Measured                    30   \n",
       "1              >75%               Measured                    29   \n",
       "2               NaN               Measured                    16   \n",
       "3              >75%               Measured  (10)-converted value   \n",
       "4              >75%               Measured  (13)-converted value   \n",
       "\n",
       "  Temporal coverage.1 note on converted PM2.5  \\\n",
       "0                >75%                Measured   \n",
       "1                >75%                Measured   \n",
       "2                 NaN                Measured   \n",
       "3                 NaN               Converted   \n",
       "4                 NaN               Converted   \n",
       "\n",
       "  Number and type of monitoring stations  \\\n",
       "0                  1 Suburban-Background   \n",
       "1                  1 Suburban-Background   \n",
       "2              1 station, traffic, urban   \n",
       "3                     1 Urban-Background   \n",
       "4                     1 Urban-Background   \n",
       "\n",
       "                           Reference for air quality  Database version (year)  \\\n",
       "0  The European Environmental Agency (EEA) [downl...                     2018   \n",
       "1  The European Environmental Agency (EEA) [downl...                     2018   \n",
       "2  European Environment Agency, Air quality e-rep...                     2016   \n",
       "3  The European Environmental Agency (EEA) [downl...                     2018   \n",
       "4  The European Environmental Agency (EEA) [downl...                     2018   \n",
       "\n",
       "  status  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Region', 'iso3', 'Country', 'City_OR_Town', 'Year',\n",
       "       'PM10_Annual_mean_ug_per_m3', 'PM10_Temporal_coverage',\n",
       "       'PM10_note_on_converted', 'PM25_Annual_mean_ug_per_m3',\n",
       "       'PM25_Temporal_coverage', 'PM25_note_on_converted',\n",
       "       'Number_and_type_of_monitoring_stations', 'Reference_for_air_quality',\n",
       "       'Database_version_in_year', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = dat.columns\n",
    "dat.columns = list(cols[:3]) + [\"City_OR_Town\", \n",
    "                                \"Year\", \n",
    "                                \"PM10_Annual_mean_ug_per_m3\", \n",
    "                                \"PM10_Temporal_coverage\", \n",
    "                                \"PM10_note_on_converted\", \n",
    "                                \"PM25_Annual_mean_ug_per_m3\", \n",
    "                                \"PM25_Temporal_coverage\", \n",
    "                                \"PM25_note_on_converted\", \n",
    "                                \"Number_and_type_of_monitoring_stations\", \n",
    "                                \"Reference_for_air_quality\", \n",
    "                                \"Database_version_in_year\", \n",
    "                                \"status\"]\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.44s/it]\n"
     ]
    }
   ],
   "source": [
    "dat.to_gbq('dragonHacks2020.particulate_matter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi = pd.read_csv('pollution_us_2000_2016.csv')\n",
    "aqi = aqi.drop(aqi.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col in aqi.columns:\n",
    "    new_cols.append(col.replace(\" \", \"_\"))\n",
    "aqi.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:15, 195.78s/it]\n"
     ]
    }
   ],
   "source": [
    "aqi.to_gbq('dragonHacks2020.pollution', project_id='graphite-store-258114')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_query = \"\"\"\n",
    "  SELECT * FROM `graphite-store-258114.dragonHacks2020.pollution`;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1000/1000 [00:00<00:00, 1891.27rows/s]\n"
     ]
    }
   ],
   "source": [
    "pollution_data = pd.read_gbq(gbq_query, project_id=\"graphite-store-258114\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution = pollution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Code</th>\n",
       "      <th>County_Code</th>\n",
       "      <th>Site_Num</th>\n",
       "      <th>Address</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>Date_Local</th>\n",
       "      <th>NO2_Units</th>\n",
       "      <th>NO2_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>SO2_Units</th>\n",
       "      <th>SO2_Mean</th>\n",
       "      <th>SO2_1st_Max_Value</th>\n",
       "      <th>SO2_1st_Max_Hour</th>\n",
       "      <th>SO2_AQI</th>\n",
       "      <th>CO_Units</th>\n",
       "      <th>CO_Mean</th>\n",
       "      <th>CO_1st_Max_Value</th>\n",
       "      <th>CO_1st_Max_Hour</th>\n",
       "      <th>CO_AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>244</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>California</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>2003-01-16</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>17.739130</td>\n",
       "      <td>...</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.6</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>1.029167</td>\n",
       "      <td>1.4</td>\n",
       "      <td>11</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>244</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>California</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>2003-03-07</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>22.347826</td>\n",
       "      <td>...</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>244</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>California</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>2003-07-19</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.8</td>\n",
       "      <td>23</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>244</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>California</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>2003-07-15</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>18.869565</td>\n",
       "      <td>...</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>1.220833</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>244</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>California</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>2003-07-29</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>18.913043</td>\n",
       "      <td>...</td>\n",
       "      <td>Parts per billion</td>\n",
       "      <td>3.391304</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Parts per million</td>\n",
       "      <td>1.825000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_Code  County_Code  Site_Num Address       State  County    City  \\\n",
       "0           6           19       244  MOBILE  California  Fresno  Fresno   \n",
       "1           6           19       244  MOBILE  California  Fresno  Fresno   \n",
       "2           6           19       244  MOBILE  California  Fresno  Fresno   \n",
       "3           6           19       244  MOBILE  California  Fresno  Fresno   \n",
       "4           6           19       244  MOBILE  California  Fresno  Fresno   \n",
       "\n",
       "   Date_Local          NO2_Units   NO2_Mean  ...          SO2_Units  SO2_Mean  \\\n",
       "0  2003-01-16  Parts per billion  17.739130  ...  Parts per billion  0.314286   \n",
       "1  2003-03-07  Parts per billion  22.347826  ...  Parts per billion  0.652174   \n",
       "2  2003-07-19  Parts per billion  28.000000  ...  Parts per billion  1.300000   \n",
       "3  2003-07-15  Parts per billion  18.869565  ...  Parts per billion  1.114286   \n",
       "4  2003-07-29  Parts per billion  18.913043  ...  Parts per billion  3.391304   \n",
       "\n",
       "   SO2_1st_Max_Value SO2_1st_Max_Hour  SO2_AQI           CO_Units   CO_Mean  \\\n",
       "0                1.6               11      NaN  Parts per million  1.029167   \n",
       "1                2.0                0      3.0  Parts per million  1.562500   \n",
       "2                2.6               11      NaN  Parts per million  1.162500   \n",
       "3                2.6               11      NaN  Parts per million  1.220833   \n",
       "4                6.0               17      9.0  Parts per million  1.825000   \n",
       "\n",
       "   CO_1st_Max_Value CO_1st_Max_Hour  CO_AQI  \n",
       "0               1.4              11    16.0  \n",
       "1               2.9               4    33.0  \n",
       "2               1.8              23    20.0  \n",
       "3               1.7               5    19.0  \n",
       "4               2.0              10    23.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollution_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for cols in pollution.columns:\n",
    "    new_cols.append(cols.replace(\"_\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State Code', 'County Code', 'Site Num', 'Address', 'State', 'County',\n",
       "       'City', 'Date Local', 'NO2 Units', 'NO2 Mean', 'NO2 1st Max Value',\n",
       "       'NO2 1st Max Hour', 'NO2 AQI', 'O3 Units', 'O3 Mean',\n",
       "       'O3 1st Max Value', 'O3 1st Max Hour', 'O3 AQI', 'SO2 Units',\n",
       "       'SO2 Mean', 'SO2 1st Max Value', 'SO2 1st Max Hour', 'SO2 AQI',\n",
       "       'CO Units', 'CO Mean', 'CO 1st Max Value', 'CO 1st Max Hour', 'CO AQI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pollution.columns = new_cols\n",
    "pollution.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vineethsuhas/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RangeIndex' object has no attribute 'dayofyear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0553f1a701dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Frequency is being set to 365.25 because we have leap years\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sin_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m365.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mfourier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cos_1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m365.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sin_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m365.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cos_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfourier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofyear\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m365.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RangeIndex' object has no attribute 'dayofyear'"
     ]
    }
   ],
   "source": [
    "# #Data Reading and treatment\n",
    "# pollution = pd.read_csv('C:/Users/rohit/Downloads/pollution_us_2000_2016.csv')\n",
    "\n",
    "# pollution_data = pd.read_gbq(gbq_query, project_id=\"graphite-store-258114\")\n",
    "\n",
    "\n",
    "#Before pre-processing \n",
    "pollution.shape\n",
    "#(1746661, 29)\n",
    "pollution['Date Local'] = pd.to_datetime(pollution['Date Local'])\n",
    "pollution = pollution[pollution['Date Local'] > '2010-12-31']\n",
    "pollution.shape\n",
    "#(674279, 29)\n",
    "\n",
    "#Checking the column names to be removed\n",
    "pollution.columns\n",
    "\n",
    "#Removing unnecessary columns\n",
    "pollution.drop(columns=['State Code','County Code','Address','NO2 Units', 'NO2 Mean','NO2 1st Max Value', 'NO2 1st Max Hour', 'O3 Units', 'O3 Mean', 'O3 1st Max Value', 'O3 1st Max Hour', 'SO2 Units','SO2 Mean', 'SO2 1st Max Value', 'SO2 1st Max Hour', 'CO Units', 'CO Mean', 'CO 1st Max Value', 'CO 1st Max Hour'], inplace=True)\n",
    "pollution.head()\n",
    "\n",
    "#(674279, 9)\n",
    "pollution.dropna(inplace=True) #drop null values\n",
    "#(168649, 9)\n",
    "\n",
    "#Aggregate AQIs'\n",
    "df = pollution.groupby(['Site Num','State','County','City','Date Local']).agg({'NO2 AQI':'mean','O3 AQI':'mean','SO2 AQI':'mean','CO AQI':'mean'})\n",
    "df.shape\n",
    "#(152179, 4)\n",
    "df.reset_index(inplace=True)\n",
    "#(152061, 9)\n",
    "\n",
    "#Checking if all cities have the data in all required years\n",
    "#df['Date Local'] = pd.to_datetime(df['Date Local'])\n",
    "#df = df[df['Date Local'] > '2010-12-31']\n",
    "df['year']=pd.DatetimeIndex(df['Date Local']).year\n",
    "inter = df.groupby('City').agg({'year': 'nunique'})\n",
    "inter = inter.reset_index()\n",
    "inter = inter[inter.year == 6]\n",
    "uniqueCity = inter.City.to_list()\n",
    "\n",
    "#Removing the cities which don't have 6 years of data\n",
    "df = df[df.City.isin(uniqueCity)]\n",
    "#(105307, 10)\n",
    "\n",
    "# Aggregating to day-level\n",
    "\n",
    "pollutants = ['no2_aqi', 'o3_aqi', 'so2_aqi', 'co_aqi']\n",
    "\n",
    "agg_data = df.groupby('Date Local').mean().drop(['Site Num','year'], axis=1)\n",
    "agg_data.index = pd.to_datetime(agg_data.index)\n",
    "agg_data.columns = pollutants\n",
    "\n",
    "#Splitting to train and test\n",
    "train = agg_data[:'2015-10-01']\n",
    "test = agg_data['2015-10-01':'2016-03-31']\n",
    "\n",
    "# Aggregating to day-level\n",
    "\n",
    "pollutants = ['no2_aqi', 'o3_aqi', 'so2_aqi', 'co_aqi']\n",
    "\n",
    "agg_data = df.groupby('Date Local').mean().drop(['Site Num','year'], axis=1)\n",
    "agg_data.index = pd.to_datetime(agg_data.index)\n",
    "agg_data.columns = pollutants\n",
    "\n",
    "#Splitting to train and test\n",
    "train = agg_data[:'2015-10-01']\n",
    "test = agg_data['2015-10-01':'2016-03-31']\n",
    "\n",
    "# Forecasting data\n",
    "# Fourier terms\n",
    "fourier = pd.DataFrame(index=agg_data[:'2016-03-31'].index)\n",
    "\n",
    "# Frequency is being set to 365.25 because we have leap years\n",
    "fourier['sin_1'] = np.sin(2 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "fourier['cos_1'] = np.cos(2 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "fourier['sin_2'] = np.sin(4 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "fourier['cos_2'] = np.cos(4 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "\n",
    "fourier_train = fourier.iloc[:train.shape[0], :]\n",
    "fourier_test = fourier.iloc[train.shape[0]-1:, :]\n",
    "\n",
    "no2_arima = auto_arima(train['no2_aqi'], exogenous=fourier_train, start_p=1, start_q=0, stepwise=True,\n",
    "                      suppress_warnings=True, error_action='ignore')\n",
    "\n",
    "o3_arima = auto_arima(train['o3_aqi'], exogenous=fourier_train, start_p=1, start_q=0,\n",
    "                      stepwise=True, suppress_warnings=True)\n",
    "\n",
    "so2_arima = auto_arima(train['so2_aqi'], exogenous=fourier_train,start_p=1, start_q=0, stepwise=True, \n",
    "                       suppress_warnings=True,error_action='ignore')\n",
    "\n",
    "co_arima =  auto_arima(train['co_aqi'],exogenous=fourier_train,start_p=1, start_q=0, \n",
    "                       stepwise=True, suppress_warnings=True)\n",
    "\n",
    "no2_predictions = no2_arima.predict(n_periods=test.shape[0], exogenous=fourier_test)\n",
    "o3_predictions  = o3_arima.predict(n_periods=test.shape[0], exogenous=fourier_test)\n",
    "so2_predictions = so2_arima.predict(n_periods=test.shape[0], exogenous=fourier_test)\n",
    "co_predictions  = co_arima.predict(n_periods=test.shape[0], exogenous=fourier_test)\n",
    "sarima_pred = pd.DataFrame(np.c_[no2_predictions, o3_predictions, so2_predictions, co_predictions],\n",
    "                           columns=test.columns, index=test.index)\n",
    "                           \n",
    "                           \n",
    "# Creating a dataframe to store arima scores\n",
    "\n",
    "s_ix = pd.MultiIndex.from_tuples([('RMSE', 'SARIMA'), ('MAE', 'SARIMA')])\n",
    "sarima_scores = pd.DataFrame(index=s_ix, columns=pollutants)\n",
    "\n",
    "for pol in pollutants:\n",
    "    pred = sarima_pred[pol]\n",
    "    rmse = np.sqrt(mean_squared_error(test[pol], pred))\n",
    "    mae = mean_absolute_error(test[pol], pred)\n",
    "    sarima_scores.loc[:,pol] = [rmse, mae]\n",
    "\n",
    "sarima_scores                           \n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################################\n",
    "\n",
    "path = 'C:/Users/rohit/Downloads/pollution_us_2000_2016.csv'\n",
    "\n",
    "def readdata(path):\n",
    "    pollution = pd.read_csv(path)\n",
    "    return pollution\n",
    "    \n",
    "def treatdata(df):\n",
    "    # Data Cleaning\n",
    "    df = df[df['Date Local'] > '2010-12-31']\n",
    "    df.drop(columns=['Unnamed: 0','State Code','County Code','Address','NO2 Units', 'NO2 Mean','NO2 1st Max Value', 'NO2 1st Max Hour', 'O3 Units', 'O3 Mean', 'O3 1st Max Value', 'O3 1st Max Hour', 'SO2 Units','SO2 Mean', 'SO2 1st Max Value', 'SO2 1st Max Hour', 'CO Units', 'CO Mean', 'CO 1st Max Value', 'CO 1st Max Hour'], inplace=True)\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    # Data Transforming\n",
    "    df1 = df.groupby(['Site Num','State','County','City','Date Local']).agg({'NO2 AQI':'mean','O3 AQI':'mean','SO2 AQI':'mean','CO AQI':'mean'})\n",
    "    df1.reset_index(inplace=True)\n",
    "    \n",
    "    #Filtering for cities which don't have data for the given time period\n",
    "    df1['year'] = pd.DatetimeIndex(df1['Date Local']).year\n",
    "    inter = df1.groupby('City').agg({'year': 'nunique'})\n",
    "    inter = inter.reset_index()\n",
    "    inter = inter[inter.year == 6]\n",
    "    uniqueCity = inter.City.to_list()\n",
    "    \n",
    "    df1 = df1[df1.City.isin(uniqueCity)]\n",
    "    \n",
    "    #Aggregating to day-level\n",
    "    pollutants = ['no2_aqi', 'o3_aqi', 'so2_aqi', 'co_aqi']\n",
    "    agg_data = df1.groupby('Date Local').mean().drop(['Site Num','year'], axis=1)\n",
    "    agg_data.index = pd.to_datetime(agg_data.index)\n",
    "    agg_data.columns = pollutants\n",
    "    return agg_data\n",
    "    \n",
    "def modeldata(agg_data, period):    \n",
    "    \n",
    "    # Entire data will go to train the model\n",
    "    train = agg_data\n",
    "    \n",
    "    fourier = pd.DataFrame(index=agg_data.index)\n",
    "    \n",
    "    fourier['sin_1'] = np.sin(2 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "    fourier['cos_1'] = np.cos(2 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "    fourier['sin_2'] = np.sin(4 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "    fourier['cos_2'] = np.cos(4 * np.pi * fourier.index.dayofyear / 365.25)\n",
    "    \n",
    "    fourier_train = fourier.iloc[:train.shape[0], :]\n",
    "    fourier_test = fourier.iloc[train.shape[0]-1:, :]\n",
    "    \n",
    "    no2_predictions = no2_arima.predict(n_periods= period, exogenous=fourier_test)\n",
    "    o3_predictions  = o3_arima.predict(n_periods= period, exogenous=fourier_test)\n",
    "    so2_predictions = so2_arima.predict(n_periods= period, exogenous=fourier_test)\n",
    "    co_predictions  = co_arima.predict(n_periods= period, exogenous=fourier_test)\n",
    "    sarima_pred = pd.DataFrame(np.c_[no2_predictions, o3_predictions, so2_predictions, co_predictions],\n",
    "                               columns=test.columns, index=test.index)\n",
    "    \n",
    "    return sarima_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sin_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sin_1]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT name, SUM(number) as total_people\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_2013`\n",
    "    WHERE state = 'TX'\n",
    "    GROUP BY name, state\n",
    "    ORDER BY total_people DESC\n",
    "    LIMIT 20\n",
    "\"\"\"\n",
    "# query_job = client.query(query)  # Make an API request.\n",
    "\n",
    "print(\"The query data:\")\n",
    "for row in query_job:\n",
    "    # Row values can be accessed by field name or index.\n",
    "    print(\"name={}, count={}\".format(row[0], row[\"total_people\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghgp2016 = pd.read_excel('/Users/vineethsuhas/vineeth/handsOn/hackathons/dragonHacks/ghgp_data_2016.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghgp2016 = ghgp2016.loc[:, ['City', 'State', 'County', 'Industry Type (sectors)', 'CO2 emissions (non-biogenic) ',\n",
    "       'Methane (CH4) emissions ', 'Nitrous Oxide (N2O) emissions ',\n",
    "       'HFC emissions', 'PFC emissions', 'SF6 emissions ', 'NF3 emissions',\n",
    "       'Other Fully Fluorinated GHG emissions', 'HFE emissions',\n",
    "       'Very Short-lived Compounds emissions', 'Other GHGs (metric tons CO2e)',\n",
    "       'Biogenic CO2 emissions (metric tons)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghgp2016.columns = ['City', 'State', 'County', 'Industry_Type_sectors',\n",
    "       'CO2 emissions_non_biogenic', 'Methane_CH4_emissions ',\n",
    "       'Nitrous_Oxide_N2O_emissions', 'HFC_emissions', 'PFC_emissions',\n",
    "       'SF6_emissions', 'NF3_emissions',\n",
    "       'Other_Fully_Fluorinated_GHG_emissions', 'HFE_emissions',\n",
    "       'Very_Short_lived_Compounds_emissions', 'Other_GHGs_metric_tons_CO2e',\n",
    "       'Biogenic_CO2_emissions_metric_tons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'County', 'Industry_Type_sectors',\n",
       "       'CO2 emissions_non_biogenic', 'Methane_CH4_emissions ',\n",
       "       'Nitrous_Oxide_N2O_emissions', 'HFC_emissions', 'PFC_emissions',\n",
       "       'SF6_emissions', 'NF3_emissions',\n",
       "       'Other_Fully_Fluorinated_GHG_emissions', 'HFE_emissions',\n",
       "       'Very_Short_lived_Compounds_emissions', 'Other_GHGs_metric_tons_CO2e',\n",
       "       'Biogenic_CO2_emissions_metric_tons'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ghgp2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghgp2016.to_csv('/Users/vineethsuhas/vineeth/handsOn/hackathons/dragonHacks/ghgp_data_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
